{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import preonpy\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils.options import Options\n",
    "from env.preon_env import Preon_env\n",
    "from agent.ddpg import DDPG\n",
    "from utils.memory import ReplayMemory\n",
    "from agent.evaluator import Evaluator\n",
    "from utils.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = Options()\n",
    "env = Preon_env(opt.env_params)\n",
    "agent = DDPG(opt.agent_params)\n",
    "evaluate = Evaluator(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_new_goal(args):\n",
    "    # np.random.uniform(-1.0,1.0)\n",
    "    desired_poured_vol = np.random.choice([100,150,200,250,300,350,400,450])\n",
    "    print(desired_poured_vol)\n",
    "    desired_poured_vol_norm = (desired_poured_vol - args.max_volume/2.0) / (args.max_volume/2.0)\n",
    "    print(desired_poured_vol_norm)\n",
    "    desired_spilled_vol_norm = (0.0 - args.max_volume/2.0) / (args.max_volume/2.0)\n",
    "    new_goal = [desired_poured_vol_norm, desired_spilled_vol_norm]\n",
    "    return new_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35897435897435898, 0.0]\n"
     ]
    }
   ],
   "source": [
    "agent.is_training = True\n",
    "goal = generate_new_goal(opt.env_params)\n",
    "print(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started simulation from frame 0 to frame 2 with 8 thread(s).\n",
      "Done simulating  2  frames.\n",
      "(0.0, 0.20000000000000001, -1.0, -1.0, -1.0)\n"
     ]
    }
   ],
   "source": [
    "observation, _ = deepcopy(env.reset())\n",
    "agent.reset(observation)\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('action:', array([ 0.25083561, -0.25995295,  0.24535936]))\n"
     ]
    }
   ],
   "source": [
    "action = to_numpy(agent.actor(to_tensor(np.array([observation])),to_tensor(np.array([goal])))).squeeze(0)\n",
    "action = agent.add_noise_to_action(action)\n",
    "action = np.clip(action, -1., 1.)\n",
    "agent.a_t = action\n",
    "print(\"action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute action in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started simulation from frame 2 to frame 3 with 8 thread(s).\n",
      "Done simulating  1  frames.\n"
     ]
    }
   ],
   "source": [
    "observation2, reward, done, info = env.step(action, goal)\n",
    "observation2 = deepcopy(observation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent.observe(goal, reward, observation2, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Transition(state=(0.0, 0.20000000000000001, -1.0, -1.0, -1.0), goal=[-0.35897435897435898, 0.0], action=array([ 0.25083561, -0.25995295,  0.24535936]), next_state=(0.041666666666666664, 0.14800000000000005, -0.98773203161027701, -1.0, -1.0), reward=1.0, terminal=False),\n",
       " Transition(state=(0.041666666666666664, 0.14800000000000005, -0.98773203161027701, -1.0, -1.0), goal=[-0.35897435897435898, 0.0], action=array([ 0.25083561, -0.25995295,  0.24535936]), next_state=(0.041666666666666664, 0.14800000000000005, -0.98773203161027701, -1.0, -1.0), reward=1.0, terminal=False),\n",
       " Transition(state=(0.041666666666666664, 0.14800000000000005, -0.98773203161027701, -1.0, -1.0), goal=[-0.35897435897435898, 0.0], action=array([ 0.25083561, -0.25995295,  0.24535936]), next_state=(0.041666666666666664, 0.14800000000000005, -0.98773203161027701, -1.0, -1.0), reward=1.0, terminal=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_batch, goal_batch, action_batch, reward_batch, \\\n",
    "next_state_batch, terminal_batch = agent.memory.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.3590  0.0000\n",
      "-0.3590  0.0000\n",
      "-0.3590  0.0000\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "Variable containing:\n",
      " 0.0417  0.1480 -0.9877 -1.0000 -1.0000\n",
      " 0.0417  0.1480 -0.9877 -1.0000 -1.0000\n",
      " 0.0417  0.1480 -0.9877 -1.0000 -1.0000\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_goal = to_tensor(goal_batch, volatile=True)\n",
    "var_next_state = to_tensor(next_state_batch, volatile=True)\n",
    "print(var_goal)\n",
    "print(var_next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0674  0.0743 -0.2082\n",
      "-0.0674  0.0743 -0.2082\n",
      "-0.0674  0.0743 -0.2082\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "next_q_values = agent.critic_target(var_next_state, var_goal,agent.actor_target(var_next_state, var_goal))\n",
    "next_q_values.volatile=False\n",
    "print(next_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
