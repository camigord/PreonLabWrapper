{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.options import Options\n",
    "from utils.utils import *\n",
    "\n",
    "from networks import RecurrentActorNetwork, RecurrentCriticNetwork\n",
    "from utils.replay_buffer_trace import ReplayBufferTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Options()\n",
    "opt.agent_params.trace_length = 5\n",
    "opt.agent_params.opt_length = 5\n",
    "opt.agent_params.state_dim = 5\n",
    "\n",
    "RANDOM_SEED = 1256\n",
    "# Size of replay buffer\n",
    "BUFFER_SIZE = opt.agent_params.rm_size\n",
    "MINIBATCH_SIZE = opt.agent_params.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actor = RecurrentActorNetwork(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "critic = RecurrentCriticNetwork(actor.get_num_trainable_vars(), opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBufferTrace(BUFFER_SIZE, opt.agent_params.trace_length, opt.save_dir, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goal = [0.4, 0.6]\n",
    "state = [0.1,0.1,50,100,0]\n",
    "\n",
    "init_actor_hidden_c = state_initialiser(shape=(1,actor.rnn_size),mode='g')\n",
    "init_actor_hidden_m = state_initialiser(shape=(1,actor.rnn_size),mode='g')\n",
    "actor_init_hidden_cm = (init_actor_hidden_c, init_actor_hidden_m)\n",
    "\n",
    "input_s = np.reshape(state, (1, 1, actor.s_dim))\n",
    "input_g = np.reshape(goal, (1, 1, actor.goal_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying action selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    actor.set_session(sess)\n",
    "    critic.set_session(sess)\n",
    "    # Initialize target network weights\n",
    "    actor.update_target_network()\n",
    "    critic.update_target_network()\n",
    "    action, actor_last_hidden_cm = actor.predict(input_s, input_g, actor_init_hidden_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action = [-1, 2, 5]\n",
    "reward = 10\n",
    "terminal = False\n",
    "\n",
    "for e in range(20):\n",
    "    episode = []\n",
    "    for i in range(5):\n",
    "        transition = [np.reshape(state, (actor.s_dim,)), np.reshape(goal, (actor.goal_dim,)),\n",
    "                          np.reshape(action, (actor.a_dim,)), reward, terminal, np.reshape(state, (actor.s_dim,))]\n",
    "        episode.append(transition)\n",
    "        \n",
    "    replay_buffer.add(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MINIBATCH_SIZE = 10\n",
    "minibatch = replay_buffer.sample_batch(MINIBATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_batch  (10, 5, 5)\n",
      "goal_batch  (10, 5, 2)\n",
      "action_batch  (10, 5, 3)\n",
      "reward_batch  (10, 5, 1)\n",
      "done_batch  (10, 5, 1)\n",
      "next_batch  (10, 6, 5)\n",
      "extra_goal_batch  (10, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "state_trace_batch = np.stack(minibatch[:,:,0].ravel()).reshape(MINIBATCH_SIZE, opt.agent_params.trace_length, actor.s_dim)\n",
    "print('state_batch ', state_trace_batch.shape)\n",
    "\n",
    "goal_trace_batch = np.stack(minibatch[:,:,1].ravel()).reshape(MINIBATCH_SIZE, opt.agent_params.trace_length, actor.goal_dim)\n",
    "print('goal_batch ', goal_trace_batch.shape)\n",
    "\n",
    "action_trace_batch = np.stack(minibatch[:,:,2].ravel()).reshape(MINIBATCH_SIZE,opt.agent_params.trace_length, actor.a_dim)\n",
    "print('action_batch ', action_trace_batch.shape)\n",
    "\n",
    "reward_trace_batch = np.stack(minibatch[:,:,3].ravel()).reshape(MINIBATCH_SIZE, opt.agent_params.trace_length, 1)\n",
    "print('reward_batch ', reward_trace_batch.shape)\n",
    "\n",
    "done_trace_batch = np.stack(minibatch[:,:,4].ravel()).reshape(MINIBATCH_SIZE, opt.agent_params.trace_length, 1)\n",
    "print('done_batch ', done_trace_batch.shape)\n",
    "\n",
    "next_state_batch = np.stack(minibatch[:,-1,5].ravel()).reshape(MINIBATCH_SIZE, 1, actor.s_dim)\n",
    "next_state_trace_batch = np.concatenate([state_trace_batch, next_state_batch],axis=1)\n",
    "\n",
    "print('next_batch ', next_state_trace_batch.shape)\n",
    "\n",
    "extra_goal_batch = np.stack(minibatch[:,-1,1].ravel()).reshape(MINIBATCH_SIZE, 1, actor.goal_dim)\n",
    "extra_goal_trace_batch = np.concatenate([goal_trace_batch, extra_goal_batch],axis=1)\n",
    "\n",
    "print('extra_goal_batch ', extra_goal_trace_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_actor_hidden_batch = state_initialiser(shape=(MINIBATCH_SIZE, actor.rnn_size), mode='z')\n",
    "actor_init_h_batch = (init_actor_hidden_batch, init_actor_hidden_batch)\n",
    "\n",
    "init_critic_hidden_batch = state_initialiser(shape=(MINIBATCH_SIZE, actor.rnn_size), mode='z')\n",
    "critic_init_h_batch = (init_critic_hidden_batch, init_critic_hidden_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, trace_length < opt_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_actor_init_h_batch = actor_init_h_batch\n",
    "target_critic_init_h_batch = critic_init_h_batch\n",
    "update_length = opt.agent_params.trace_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init_op)\n",
    "actor.set_session(sess)\n",
    "critic.set_session(sess)\n",
    "# Initialize target network weights\n",
    "actor.update_target_network()\n",
    "critic.update_target_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 5) (10, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(next_state_trace_batch.shape, goal_trace_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "next_action_batch = actor.predict_target(next_state_trace_batch, extra_goal_trace_batch, target_actor_init_h_batch)\n",
    "print(next_action_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "next_action_trace_batch = np.concatenate([action_trace_batch, np.expand_dims(next_action_batch, axis=1)], axis=1)\n",
    "print(next_action_trace_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "target_q_batch = critic.predict_target(next_state_trace_batch, extra_goal_trace_batch, next_action_trace_batch, target_critic_init_h_batch)\n",
    "print(target_q_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "target_lastQ_batch_masked = target_q_batch * (1.- done_trace_batch[:,-1])\n",
    "print(target_lastQ_batch_masked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "rQ = np.concatenate([np.squeeze(reward_trace_batch[:,-update_length:],axis=-1), target_lastQ_batch_masked],axis=1)\n",
    "print(rQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discounting_mat_dict = {}\n",
    "try:\n",
    "    # If already defined\n",
    "    discounting_mat = discounting_mat_dict[update_length]\n",
    "except KeyError:\n",
    "    discounting_mat = np.zeros(shape=(update_length,update_length+1),dtype=np.float)\n",
    "    for i in range(update_length):\n",
    "        discounting_mat[i,:i] = 0.\n",
    "        discounting_mat[i,i:] = 2 ** np.arange(0.,-i+update_length+1)\n",
    "    discounting_mat = np.transpose(discounting_mat)\n",
    "    discounting_mat_dict[update_length] = discounting_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: array([[  1.,   0.,   0.,   0.,   0.],\n",
       "        [  2.,   1.,   0.,   0.,   0.],\n",
       "        [  4.,   2.,   1.,   0.,   0.],\n",
       "        [  8.,   4.,   2.,   1.,   0.],\n",
       "        [ 16.,   8.,   4.,   2.,   1.],\n",
       "        [ 32.,  16.,   8.,   4.,   2.]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounting_mat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "y_trace_batch = np.expand_dims(np.matmul(rQ, discounting_mat), axis=-1)\n",
    "print(y_trace_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "predicted_q_value, _, v_loss = critic.train(state_trace_batch,\n",
    "                                            goal_trace_batch,\n",
    "                                            action_trace_batch,\n",
    "                                            y_trace_batch,\n",
    "                                            update_length, critic_init_h_batch)\n",
    "print(predicted_q_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(update_length):\n",
    "    actor_init_h_batch_trace = (np.expand_dims(actor_init_h_batch[0],axis=1), np.expand_dims(actor_init_h_batch[1],axis=1))\n",
    "    critic_init_h_batch_trace = (np.expand_dims(critic_init_h_batch[0],axis=1), np.expand_dims(critic_init_h_batch[1],axis=1))\n",
    "    if i == 0:\n",
    "        actor_init_h_batch_stack = actor_init_h_batch_trace\n",
    "        critic_init_h_batch_stack = critic_init_h_batch_trace\n",
    "    else:\n",
    "        actor_init_h_batch_stack = (np.concatenate((actor_init_h_batch_stack[0],actor_init_h_batch_trace[0]),axis=1),np.concatenate((actor_init_h_batch_stack[1],actor_init_h_batch_trace[1]),axis=1))\n",
    "        critic_init_h_batch_stack = (np.concatenate((critic_init_h_batch_stack[0],critic_init_h_batch_trace[0]),axis=1),np.concatenate((critic_init_h_batch_stack[1],critic_init_h_batch_trace[1]),axis=1))\n",
    "\n",
    "    #print(actor_init_h_batch.shape)\n",
    "    action_trace_batch_for_gradients, actor_init_h_batch = actor.action_trace(np.expand_dims(state_trace_batch[:,i],1),\n",
    "                                                                              np.expand_dims(goal_trace_batch[:,i],1),\n",
    "                                                                              actor_init_h_batch)\n",
    "    critic_init_h_batch = critic.predict(np.expand_dims(state_trace_batch[:,i],1),\n",
    "                                                np.expand_dims(goal_trace_batch[:,i],1),\n",
    "                                                np.expand_dims(action_trace_batch[:,i],1), critic_init_h_batch, mode = 1)\n",
    "    if i == 0:\n",
    "        action_trace_batch_for_gradients_stack = action_trace_batch_for_gradients\n",
    "    else:\n",
    "        action_trace_batch_for_gradients_stack = np.concatenate((action_trace_batch_for_gradients_stack,action_trace_batch_for_gradients),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state  (50, 1, 5)\n",
      "action  (50, 1, 3)\n",
      "goal  (50, 1, 2)\n",
      "action_trace  (50, 1, 3)\n",
      "(50, 200) (50, 200)\n",
      "(50, 200) (50, 200)\n"
     ]
    }
   ],
   "source": [
    "state_trace_batch_stack = np.reshape(state_trace_batch,(MINIBATCH_SIZE*update_length, 1, actor.s_dim))\n",
    "print('state ', state_trace_batch_stack.shape)\n",
    "action_trace_batch_stack = np.reshape(action_trace_batch,(MINIBATCH_SIZE*update_length, 1, actor.a_dim))\n",
    "print('action ', action_trace_batch_stack.shape)\n",
    "goal_trace_batch_stack = np.reshape(goal_trace_batch,(MINIBATCH_SIZE*update_length, 1, actor.goal_dim))\n",
    "print('goal ', goal_trace_batch_stack.shape)\n",
    "action_trace_batch_for_gradients_stack = np.reshape(action_trace_batch_for_gradients_stack,(MINIBATCH_SIZE*update_length, 1, actor.a_dim))\n",
    "print('action_trace ', action_trace_batch_for_gradients_stack.shape)\n",
    "actor_init_h_batch_stack = (np.reshape(actor_init_h_batch_stack[0],(MINIBATCH_SIZE*update_length, actor.rnn_size)), np.reshape(actor_init_h_batch_stack[1],(MINIBATCH_SIZE*update_length, actor.rnn_size)))\n",
    "print(actor_init_h_batch_stack[0].shape, actor_init_h_batch_stack[1].shape)\n",
    "critic_init_h_batch_stack = (np.reshape(critic_init_h_batch_stack[0],(MINIBATCH_SIZE*update_length, critic.rnn_size)), np.reshape(critic_init_h_batch_stack[1],(MINIBATCH_SIZE*update_length, critic.rnn_size)))\n",
    "print(critic_init_h_batch_stack[0].shape, critic_init_h_batch_stack[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "q_gradient_trace_batch = critic.action_gradients(state_trace_batch_stack,\n",
    "                                                 goal_trace_batch_stack,\n",
    "                                                 action_trace_batch_for_gradients_stack,\n",
    "                                                 1,\n",
    "                                                 critic_init_h_batch_stack)\n",
    "print(q_gradient_trace_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actor.train(state_trace_batch_stack,\n",
    "             goal_trace_batch_stack,\n",
    "             q_gradient_trace_batch,\n",
    "             1,\n",
    "             actor_init_h_batch_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor.update_target_network()\n",
    "critic.update_target_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfuly saved: RDPG Buffer\n",
      "Buffer length saved: 20\n"
     ]
    }
   ],
   "source": [
    "replay_buffer.save_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = False\n",
    "if not a:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.75"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [3,5,7,8]\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
